insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://forum.effectivealtruism.org/posts/uK27pds7J36asqJPt/future-of-humanity-institute-2005-2024-final-report', /* url */
        'Future of Humanity Institute 2005-2024: Final Report', /* title */
        '2024-04-17', /* publication_date */
        NULL, /* modified_date */
        'Pablo', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'Building effective altruism', /* cause_area */
        'Sandberg''s final report on the Future of Humanity Institute (FHI) reflects on its successes and challenges from 2005 to 2024, highlighting FHI''s impact on long-term research fields, interdisciplinary collaboration, and operational insights for future existential risk research.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/WTBqQbzqW894aZL6u/future-of-humanity-institute-is-hiring', /* url */
        'Future of Humanity Institute is hiring', /* title */
        '2015-12-08', /* publication_date */
        NULL, /* modified_date */
        'Andrew_SB', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Andrew_SB provides a brief on the Future of Humanity Institute’s 2015 hiring for research roles focused on AI safety, policy, strategy, and existential risk, highlighting the institute''s mission to tackle civilization-scale challenges.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gLpAai6D3HertcXhQ/research-position-at-future-of-humanity-institute', /* url */
        'Research position at Future of Humanity Institute', /* title */
        '2015-04-15', /* publication_date */
        NULL, /* modified_date */
        'Daniel Dewey', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Dewey announces the Future of Humanity Institute’s call for a Postdoctoral Research Fellow to conduct AI safety research with Professor Nick Bostrom, emphasizing a long-term focus on machine intelligence risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/XyYxLzdxNzhCZFsci/throwing-the-institutional-baby-out-with-the-bathwater', /* url */
        'Throwing the institutional baby out with the bathwater: Physicist & YouTuber Sabine Hossenfelder''s superficial and sensationalist take on the demise of the Future of Humanity Institute', /* title */
        '2024-05-02', /* publication_date */
        NULL, /* modified_date */
        'Deborah W.A. Foulkes', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        'Sabine Hossenfelder', /* affected_people */
        'General discussion of organizational practices', /* document_scope */
        'AI safety', /* cause_area */
        'Foulkes critiques Sabine Hossenfelder''s video for undermining the Future of Humanity Institute''s significant work on AI risks and global regulation efforts amid recent challenges.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/4HcggJWghXogSS25b/job-opportunity-at-the-future-of-humanity-institute-and', /* url */
        'Job opportunity at the Future of Humanity Institute and Global Priorities Institute', /* title */
        '2018-04-18', /* publication_date */
        NULL, /* modified_date */
        'HaydenW', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        'Sabine Hossenfelder', /* affected_people */
        'Hiring-related notice', /* document_scope */
        'Building effective altruism', /* cause_area */
        'HaydenW highlights the Future of Humanity Institute''s need for a Senior Administrator to support its expansion in operations, covering finance, HR, and strategic management to drive long-term impact.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/5vGsFzWvh8Snet6sK/the-centre-for-the-governance-of-ai-has-relaunched', /* url */
        'The Centre for the Governance of AI has Relaunched', /* title */
        '2021-10-29', /* publication_date */
        NULL, /* modified_date */
        'GovAI', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'GovAI relaunches as a nonprofit in Oxford alongside the Future of Humanity Institute, expanding research, fellowships, and policy advising in AI governance.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/5vGsFzWvh8Snet6sK/the-centre-for-the-governance-of-ai-has-relaunched', /* url */
        'Differential technology development: preprint on the concept', /* title */
        '2022-09-12', /* publication_date */
        NULL, /* modified_date */
        'Hamish Hobbs| jbs| Allan Dafoe', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Hobbs, Sandbrink, Swett, Dafoe, and Sandberg at the Future of Humanity Institute present a preprint on differential technology development, advocating for prioritizing risk-reducing over risk-increasing technologies to mitigate existential threats from advanced AI and biotech.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/4BJSXH9ho4eYNT73P/how-dependent-is-the-effective-altruism-movement-on-dustin', /* url */
        'How Dependent is the Effective Altruism Movement on Dustin Moskovitz and Cari Tuna?', /* title */
        '2020-09-21', /* publication_date */
        NULL, /* modified_date */
        'Sapphire', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Benjamin Todd’s analysis shows that the Effective Altruism (EA) community infrastructure relies significantly on Good Ventures, with Dustin Moskovitz and Cari Tuna contributing an estimated 50-66% of total EA funding, supporting major organizations like the Future of Humanity Institute, which received £13.3 million in 2018 from the Open Philanthropy Project.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/bG9ZNvSmveNwryx8b/ama-owen-cotton-barratt-rsp-director', /* url */
        'AMA: Owen Cotton-Barratt, RSP Director', /* title */
        '2020-08-28', /* publication_date */
        NULL, /* modified_date */
        'Owen Cotton-Barratt', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Owen Cotton-Barratt discusses his role at the Future of Humanity Institute, focusing on the Research Scholars Programme and his research on decision-making under uncertainty, AI''s impact on effective altruism, and strategies to avoid catastrophic human behavior.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/7gxtXrMeqw78ZZeY9/ama-or-discuss-my-80k-podcast-episode-ben-garfinkel-fhi', /* url */
        'AMA or discuss my 80K podcast episode: Ben Garfinkel, FHI researcher', /* title */
        '2020-07-13', /* publication_date */
        NULL, /* modified_date */
        'Bgarfinkel', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Ben Garfinkel, a researcher at the Future of Humanity Institute, discusses AI safety, governance, and long-termist arguments in a podcast, offering insights into the importance of AI risk research and critiquing classic "fast takeoff" arguments.' /* notes */
    )
    
    ;

      