insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://forum.effectivealtruism.org/posts/j5xhPbj7ywdv6aEJc/ama-future-of-life-institute-s-eu-team', /* url */
        'AMA: Future of Life Institute''s EU Team', /* title */
        '2022-01-31', /* publication_date */
        NULL, /* modified_date */
        'Risto Uuk', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Risto Uuk and Mark Brakel of the Future of Life Institute''s EU team discuss their work on AI safety and governance, including the institute''s AI risk mitigation efforts and their hiring of a new EU Policy Analyst.' /* notes */
    )
      ,(
        'https://forum.effectivealtruism.org/posts/44XPFrHiFwFBM2jfL/an-appraisal-of-the-future-of-life-institute-ai-existential',  /* url */
        'An appraisal of the Future of Life Institute AI existential risk program', /* title */
        '2022-12-11', /* publication_date */
        NULL, /* modified_date */
        'PabloAMC', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article appreciates the Future of Life Institute''s efforts in establishing an AI existential risk community and its contribution to AI safety through initiatives like the Vitalik Buterin PhD and postdoc fellowships.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/eaWSC7QXJX3sP4zry/the-future-of-life-institute-is-hiring',  /* url */
        'The Future of Life Institute is Hiring', /* title */
        '2023-09-19', /* publication_date */
        NULL, /* modified_date */
        'Palus Astra', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Astra provides an overview of the Future of Life Institute''s recent hiring announcement for a project coordinator role, highlighting the skills and responsibilities required for the position.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/8KhGio2rhgHgsBoZ6/a-summary-of-current-work-in-ai-governance',  /* url */
        'A summary of current work in AI governance', /* title */
        '2023-06-17', /* publication_date */
        NULL, /* modified_date */
        'Constructive', /* author */
       'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article provides a summary of recent work in AI governance, highlighting key organizations like the Future of Life Institute, which is focused on addressing risks from advanced AI and fostering collaboration among stakeholders to ensure beneficial outcomes.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/D8NfyuQeGspM9fYpT/begging-pleading-ai-orgs-to-comment-on-nist-ai-risk',  /* url */
        'Begging, Pleading AI Orgs to Comment on NIST AI Risk Management Framework', /* title */
        '2022-12-15', /* publication_date */
        NULL, /* modified_date */
         NULL, /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article urges AI safety and alignment organizations, such as Future of Life Institute, to provide public comments on NIST''s AI Risk Management Framework to influence its development and incorporate safeguards against potential AI risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/wFC3axfuwABHmoQ9H/the-vitalik-buterin-fellowship-in-ai-existential-safety-is',  /* url */
        'The Vitalik Buterin Fellowship in AI Existential Safety is open for applications!', /* title */
        '2022-10-14', /* publication_date */
        NULL, /* modified_date */
        'Cynthia Chen', /* author */
       'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The Future of Life Institute is offering the 2023 Vitalik Buterin Fellowship in AI Existential Safety, providing funding for PhD and postdoctoral researchers focused on minimizing existential risks from AI.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/Htq8ucEFXp9EEiYBn/announcing-the-ai-safety-summit-talks-with-yoshua-bengio',  /* url */
        'Announcing the AI Safety Summit Talks with Yoshua Bengio"', /* title */
        '2024-05-15', /* publication_date */
        NULL, /* modified_date */
        'Otto', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Life Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article announces the AI Safety Summit Talks, featuring key figures like Max Tegmark from the Future of Life Institute, aimed at addressing AI existential risks through public debate and governance discussions.' /* notes */
    )
    
;