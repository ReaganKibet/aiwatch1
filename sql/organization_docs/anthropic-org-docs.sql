insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://www.anthropic.com/news/core-views-on-ai-safety', /* url */
        'Core Views on AI Safety: When, Why, What, and How', /* title */
        '2023-03-08', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The blog post outlines Anthropic''s key perspectives on AI safety, focusing on the potential risks of AI misalignment, timelines for addressing these concerns, and strategic approaches for mitigating long-term harms.' /* notes */
    )
      ,(
        'https://www.anthropic.com/news/uk-ai-safety-summit',  /* url */
        'Dario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy', /* title */
        '2023-11-03', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'An overview of Anthropic''s Responsible Scaling Policy (RSP), outlining their approach to monitoring AI risks, implementing safety measures, and encouraging regulatory frameworks for responsible AI development.' /* notes */
    )
     ,(
        'https://www.anthropic.com/news/anthropics-responsible-scaling-policy',  /* url */
        'Anthropic''s Responsible Scaling Policy', /* title */
        '2023-09-19', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post announcing the release of Anthropic''s Responsible Scaling Policy (RSP), outlining protocols to manage catastrophic risks posed by increasingly advanced AI systems.' /* notes */
    )
    ,(
        'https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety',  /* url */
        'Frontier Threats Red Teaming for AI Safety', /* title */
        '2023-06-26', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post detailing Anthropic''s approach to frontier threats red teaming, focusing on biological risks, findings from their red teaming efforts, and plans to scale up evaluations and mitigations for AI safety' /* notes */
    )
    ,(
        'https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback',  /* url */
        'Constitutional AI: Harmlessness from AI Feedback', /* title */
        '2022-12-15', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A research article discussing methods for training AI systems to self-supervise and improve their behavior through Constitutional AI, combining supervised learning and reinforcement learning without human-labeled harmful outputs.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/pbNDtCx3hAR6th4kc/rishi-sunak-mentions-existential-threats-in-talk-with-openai',  /* url */
        'Rishi Sunak mentions "existential threats" in talk with OpenAI, DeepMind, Anthropic CEOs', /* title */
        '2023-05-25', /* publication_date */
        NULL, /* modified_date */
        'Arjun Panickssery', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|DeepMind', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Arjun Panickssery summarizes a discussion between the UK Prime Minister and CEOs on the risks of AI, covering issues like disinformation and existential threats, along with safety measures and international collaboration.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/aTQmYafRSqe4xBkeH/jan-leike-i-m-excited-to-join-anthropicai-to-continue-the',  /* url */
        'Jan Leike: "I''m excited to join @AnthropicAI to continue the superalignment mission!"', /* title */
        '2024-05-28', /* publication_date */
        NULL, /* modified_date */
        'Defun', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        'Jan Leike', /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Jan Leike announcing his new position at Anthropic AI, where he expresses enthusiasm for continuing his work in AI alignment and safety.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/PFD8MJBEmpZLe54x9/anthropic-announces-new-s-o-t-a-claude-3',  /* url */
        'Anthropic Announces new S.O.T.A. Claude 3"', /* title */
        '2024-03-04', /* publication_date */
        NULL, /* modified_date */
        'Joseph Miller', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Joseph Miller announcing the release of Anthropic''s state-of-the-art Claude 3 model, highlighting its new capabilities and advancements in AI safety research.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/DfnaKtqeKPAM8mJwD/podcast-tamera-lanham-on-ai-risk-threat-models-alignment',  /* url */
        'Podcast: Tamera Lanham on AI risk, threat models, alignment proposals, externalized reasoning oversight, and working at Anthropic"', /* title */
        '2022-12-21', /* publication_date */
        NULL, /* modified_date */
        'Akash', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A summary of an interview with Tamera Lanham, a research resident at Anthropic, discussing her journey into AI alignment, her work on externalized reasoning oversight, and her insights on AI risks and safety.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/jmfayiD4x9DGnFAhD/ai-safety-newsletter-37-us-launches-antitrust-investigations',  /* url */
        'AI Safety Newsletter #37: US Launches Antitrust Investigations Plus, recent criticisms of OpenAI and Anthropic, and a summary of Situational Awareness"', /* title */
        '2024-06-18', /* publication_date */
        NULL, /* modified_date */
        'Center for AI Safety| Corin Katzke| AlexaPanYue| Julius| Dan H', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|Microsoft|Nvidia', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'A newsletter from the Center for AI Safety covering recent antitrust investigations into Nvidia, OpenAI, and Microsoft, along with developments in AI safety and governance.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/N28dn7J4FF9AaWbTN/197-on-whether-anthropic-s-ai-safety-policy-is-up-to-the',  /* url */
        '#197 – On whether Anthropic''s AI safety policy is up to the task (Nick Joseph on The 80,000 Hours Podcast)"', /* title */
        '2024-08-22', /* publication_date */
        NULL, /* modified_date */
        '80000_Hours', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'An interview with Nick Joseph by 80,000 Hours discussing Anthropic''s responsible scaling policy and the challenges of ensuring AI safety as capabilities increase.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/75KAanpuYFJBfAkhp/anthropic-google-microsoft-and-openai-announce-executive',  /* url */
        'Anthropic, Google, Microsoft & OpenAI announce Executive Director of the Frontier Model Forum & over $10 million for a new AI Safety Fund', /* title */
        '2024-10-25', /* publication_date */
        NULL, /* modified_date */
        'Zach Stein-Perlman', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|Microsoft|Google', /* affected_organizations */
         NULL, /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Zach Stein-Perlman announcing the appointment of Chris Meserole as Executive Director of the Frontier Model Forum, backed by Anthropic, Google, Microsoft, and OpenAI, alongside the launch of a $10 million AI Safety Fund supported by philanthropic partners to advance research in AI safety.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/JgAvau7rhmMGwscBA/would-an-anthropic-openai-merger-be-good-for-ai-safety',  /* url */
        'Would an Anthropic/OpenAI merger be good for AI safety?', /* title */
        '2023-11-22', /* publication_date */
        NULL, /* modified_date */
        'M', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'M reports that OpenAI''s board, including two Effective Altruists (EAs), considered a merger with Anthropic, which is more safety-focused, potentially leading to less competition and a slower pace in AI development.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/DDDyTvuZxoKStm92M/ai-safety-needs-great-engineers',  /* url */
        'AI Safety Needs Great Engineers', /* title */
        '2021-11-24', /* publication_date */
        NULL, /* modified_date */
        'Andy Jones', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Andy Jones outlines the urgent need for skilled engineers in AI safety labs like Anthropic, emphasizing the role of engineers in building custom infrastructure for AI experiments and encouraging those capable of contributing to major machine learning libraries to apply.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/snto3JZs6HrgvsoJG/the-tech-industry-is-the-biggest-blocker-to-meaningful-ai',  /* url */
        'The Tech Industry is the Biggest Blocker to Meaningful AI Safety Regulations', /* title */
        '2024-08-16', /* publication_date */
        NULL, /* modified_date */
        'Garrison', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Benjamin Todd discusses the potential crash of AI stocks, its implications for AI safety, and the impact it may have on funding, public sentiment, and long-term AI timelines.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gkfMLX4NWZdmpikto/critiques-of-prominent-ai-safety-labs-conjecture',  /* url */
        'Critiques of prominent AI safety labs: Conjecture', /* title */
        '2023-06-12', /* publication_date */
        NULL, /* modified_date */
        'Omega', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Omega critiques prominent AI safety labs, with a focus on Anthropic, analyzing their approaches and effectiveness in advancing AI safety.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/Y2xbKLjEmL6dCd2Z6/uk-government-to-host-first-global-summit-on-ai-safety',  /* url */
        'UK government to host first global summit on AI Safety', /* title */
        '2023-06-08', /* publication_date */
        NULL, /* modified_date */
        'David Nash', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|Google DeepMind', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'David Nash highlights Anthropic''s commitment to AI safety, with CEO Dario Amodei emphasizing the importance of global collaboration, as the UK strengthens its position in AI development with key partnerships and initiatives.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/h22mEkh9o5vCQE8Ti/dario-amodei-machines-of-loving-grace', /* url */
        'Dario Amodei — Machines of Loving Grace', /* title */
        '2024-10-12', /* publication_date */
        NULL, /* modified_date */
        'Matrice Jacobine', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        'Dario Amodei', /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article by Matrice Jacobine focuses on Anthropic CEO Dario Amodei''s perspective on the potential positive impact of AI, emphasizing that addressing AI risks is crucial to unlocking its transformative benefits.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/fKMPa7cxSnBCymuRm/is-pausing-ai-possible', /* url */
        'Is Pausing AI Possible?', /* title */
        '2024-10-12', /* publication_date */
        NULL, /* modified_date */
        'Richard Annilo', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Richard Annilo, the author explores the challenges and feasibility of pausing AI development, with a significant focus on Anthropic’s efforts and strategies in addressing AI risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how', /* url */
        'Anthropic: Core Views on AI Safety: When, Why, What, and How', /* title */
        '2023-03-09', /* publication_date */
        NULL, /* modified_date */
        'Jonmenaster', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article by Jon Menaster offers a comprehensive overview of Anthropic''s core views on AI safety, addressing the timeline, reasons, focus areas, and approaches to mitigating AI-related risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/WDeKmM87KB6NLKuBm/has-anthropic-already-made-the-externally-legible', /* url */
        'Has Anthropic already made the externally legible commitments that it planned to make?', /* title */
        '2024-03-12', /* publication_date */
        NULL, /* modified_date */
        'Ofer', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article, written by Ofer and answered by Neel Nanda, discusses whether Anthropic has made its promised externally legible commitments regarding the development of AI models beyond a certain capability threshold, with reference to their Responsible Scaling Policy..' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gbPthwLw3NovHAJdp/software-engineering-career-review', /* url */
        'Software engineering - Career review', /* title */
        '2022-02-08', /* publication_date */
        NULL, /* modified_date */
        ' Benjamin Hilton| 80000_Hours', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|Ought| Secure DNA Project|Momentum|Telis Bioscience ', /* affected_organizations */
        NULL, /* affected_people */
        'Job experince', /* document_scope */
        NULL, /* cause_area */
        'The article provides an overview of Anthropic''s recent software engineering hiring practices, focusing on lessons learned during the recruitment process.' /* notes */
    ) 
     
;
