insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://www.anthropic.com/news/core-views-on-ai-safety', /* url */
        'Core Views on AI Safety: When, Why, What, and How', /* title */
        '2023-03-08', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The blog post outlines Anthropic''s key perspectives on AI safety, focusing on the potential risks of AI misalignment, timelines for addressing these concerns, and strategic approaches for mitigating long-term harms.' /* notes */
    )
      ,(
        'https://www.anthropic.com/news/uk-ai-safety-summit',  /* url */
        'Dario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy', /* title */
        '2023-11-03', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'An overview of Anthropic''s Responsible Scaling Policy (RSP), outlining their approach to monitoring AI risks, implementing safety measures, and encouraging regulatory frameworks for responsible AI development.' /* notes */
    )
     ,(
        'https://www.anthropic.com/news/anthropics-responsible-scaling-policy',  /* url */
        'Anthropic''s Responsible Scaling Policy', /* title */
        '2023-09-19', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post announcing the release of Anthropic''s Responsible Scaling Policy (RSP), outlining protocols to manage catastrophic risks posed by increasingly advanced AI systems.' /* notes */
    )
    ,(
        'https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety',  /* url */
        'Frontier Threats Red Teaming for AI Safety', /* title */
        '2023-06-26', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post detailing Anthropic''s approach to frontier threats red teaming, focusing on biological risks, findings from their red teaming efforts, and plans to scale up evaluations and mitigations for AI safety' /* notes */
    )
    ,(
        'https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback',  /* url */
        'Constitutional AI: Harmlessness from AI Feedback', /* title */
        '2022-12-15', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A research article discussing methods for training AI systems to self-supervise and improve their behavior through Constitutional AI, combining supervised learning and reinforcement learning without human-labeled harmful outputs.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/pbNDtCx3hAR6th4kc/rishi-sunak-mentions-existential-threats-in-talk-with-openai',  /* url */
        'Rishi Sunak mentions "existential threats" in talk with OpenAI, DeepMind, Anthropic CEOs', /* title */
        '2023-05-25', /* publication_date */
        NULL, /* modified_date */
        'Arjun Panickssery', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|DeepMind', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Arjun Panickssery summarizes a discussion between the UK Prime Minister and CEOs on the risks of AI, covering issues like disinformation and existential threats, along with safety measures and international collaboration.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/aTQmYafRSqe4xBkeH/jan-leike-i-m-excited-to-join-anthropicai-to-continue-the',  /* url */
        'Jan Leike: "I''m excited to join @AnthropicAI to continue the superalignment mission!"', /* title */
        '2024-05-28', /* publication_date */
        NULL, /* modified_date */
        'Defun', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        'Jan Leike', /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Jan Leike announcing his new position at Anthropic AI, where he expresses enthusiasm for continuing his work in AI alignment and safety.' /* notes */
    )
;
